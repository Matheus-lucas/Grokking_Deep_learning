{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1  Gradient Descent Learning with Multiple Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ele_mult(number,vector):\n",
    "    output=np.zeros([len(vector)])\n",
    "    assert(len(output)==len(vector))\n",
    "    output=np.dot(number,vector)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_networking(input1,weights1):\n",
    "    assert(len(input1)==len(weights1))\n",
    "    return np.dot(input1,weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21899999999999992, 0.2091, -0.08320000000000002]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wirec = [0.65, 0.8, 0.8, 0.9 ]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary=[1, 1, 0, 1]\n",
    "true = win_or_lose_binary[0]\n",
    "input1=[toes[0],wirec[0],nfans[0]]\n",
    "\n",
    "weights=[0.1, 0.2, -0.1]\n",
    "pred = neural_networking(input1,weights)\n",
    "error=(pred - true)**2\n",
    "delta = pred- true\n",
    "weight_deltas =  ele_mult(delta,input1)\n",
    "alpha = 0.1\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= alpha * weight_deltas[i]\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4  Freezing One Weight - What Does It Do?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21899999999999992, 0.03407287500000014, -0.40632699999999977]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = neural_networking(input1,weights)\n",
    "error=(pred - true)**2\n",
    "delta = pred- true\n",
    "weight_deltas =  ele_mult(delta,input1)\n",
    "weight_deltas[0] = 0\n",
    "alpha = 0.3\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= alpha * weight_deltas[i]\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you will be surprised to see that (a) still fi nds the bottom of the bowl? Why is this? Well, the curves are a measure of each individual weig ht relative to the global error. Th us, since the error is shared, when one weight fi nds the bottom of the bowl, all the weights fi nd the bottom of the bowl.  \n",
    "\n",
    "\n",
    "First of all, if we converged (reached error = 0 ) with (b) and (c) weights and then tried to train (a), (a) wouldn't move! Why? error = 0 which means weight_delt is 0! Th is reveals a potentailly damaging property of neural networks. (a) might be a really powerful input with lots of predictive power, bu t if the network accidentally fi gures how how to predict accurately on the training data without it, then it will never learn to incorporate (a) into its prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5  Gradient Descent Learning with Multiple Outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_networking2(input1,weights1):\n",
    "    return np.dot(input1,weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.293825, 0.25655, 0.868475]\n",
      "Weight Delta: [ 0.06175 -0.5655   0.31525]\n"
     ]
    }
   ],
   "source": [
    "wirec = [0.65, 1, 1, 0.9 ]\n",
    "\n",
    "hurt= [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1,1,0,1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "weights=[0.3, 0.2, 0.9]\n",
    "\n",
    "input1= wirec[0]\n",
    "true= [hurt[0], win[0], sad[0]]\n",
    "\n",
    "error=np.zeros([len(true)])\n",
    "delta=np.zeros([len(true)])\n",
    "\n",
    "pred=neural_networking2(input1,weights)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    error[i]=(pred[i]-true[i])**2\n",
    "    delta[i]=pred[i]-true[i]\n",
    "    \n",
    "weights_delta= ele_mult(input1,delta)\n",
    "\n",
    "alpha =0.1\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= (weights_delta[i]*alpha)\n",
    "               \n",
    "print(\"Weights: {}\".format(weights))\n",
    "print(\"Weight Delta: {}\".format(weights_delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6  Gradient Descent with Multiple Inputs & Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    output[i]=np.dot(vect,matrix[i])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "       #toes  #win  #fans\n",
    "weights=[[0.1, 0.1, -.3], #hurt?\n",
    "         [0.1, 0.2, 0.0], #win?\n",
    "         [0.0, 1.3, 0.1]] #sad?\n",
    "\n",
    "# make the dot product of the vector and each amtrix line\n",
    "def vect_mat_mult(vect, matrix):\n",
    "    assert(len(vect)==len(matrix))\n",
    "    output=[0,0,0]\n",
    "    for i in range(len(vect)):\n",
    "        output[i]=np.dot(vect,matrix[i])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_networking3(input2, weights):\n",
    "    pred = vect_mat_mult(input2, weights)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate each \"weight_delta\" and putting if on each weight\n",
    "def outer_prod(vec_a,vec_b):\n",
    "    out=np.zeros([len(vec_a),len(vec_b)])\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            out[i][j]= vec_a[i] * vec_b[j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wirec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1,1,0,1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha= 0.01\n",
    "\n",
    "input1 = [toes[0], wirec[0],nfans[0]]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "pred = neural_networking3(input1, weights)\n",
    "\n",
    "error =np.zeros([len(input1)])\n",
    "delta = np.zeros([len(input1)])\n",
    "\n",
    "for i in range(len(true)):\n",
    "    error[i]=(pred[i] - true[i])**2\n",
    "    delta[i]= pred[i] - true[i]\n",
    "\n",
    "# return the weight_delta(input*delta)\n",
    "weights_delta=outer_prod(input1, delta)\n",
    "\n",
    "#update the weights\n",
    "for i in range(len(weights)):\n",
    "    for j in range(len(weights[0])):\n",
    "        weights[i][j] -= alpha * weights_delta[i][j]\n",
    "print(\"Weights: \",weights,sep=\"\\n\")\n",
    "\n",
    "print(\"Weights Delta: \", weights_delta,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7  What do these weights learn?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are the correlation between the inputs and the outputs. the dot product show how the weight and the input vector are equals, if this product is high, they are very similar vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
